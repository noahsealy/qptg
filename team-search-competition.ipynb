{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qtpg.team import Team\n",
    "from qtpg.learner import Learner\n",
    "from qtpg.program import Program\n",
    "from qtpg.rule import Rule\n",
    "from qtpg.figure13 import Figure13\n",
    "from qtpg.figure13_hole_in_wall import Figure13HoleInWall\n",
    "from qtpg.figure12 import Figure12\n",
    "from qtpg.figure9 import Figure9\n",
    "from qtpg.figureRandom import FigureRandom\n",
    "from qtpg.figureHeywood import FigureHeywood\n",
    "from qtpg.search_manager import SearchManager\n",
    "from qtpg.results_manager import ResultsManager\n",
    "import numpy as np\n",
    "import uuid\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_query_env = 0\n",
    "gp_query_runs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# env params\n",
    "memorySize = 40\n",
    "legalMove = 0.1\n",
    "illegalMove = -0.01\n",
    "outOfBounds = 0.0\n",
    "memoryRepeat = -0.01\n",
    "goalReached = 100\n",
    "\n",
    "# envName = 'Figure 13 no reinforcements'\n",
    "# env = Figure13(5, 5, (2, 4), (0, 0), memorySize, 0.1, -0.01, 0.0, -0.01, 0.1)\n",
    "# envName = 'Figure 13'\n",
    "# env = Figure13(5, 5, (2, 4), (0, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Figure 13 Hole in Wall'\n",
    "# env = Figure13HoleInWall(5, 5, (2, 4), (0, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Figure 12'\n",
    "# env = Figure12(5, 5, (4, 4), (0, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Figure 9'\n",
    "# env = Figure9(10, 10, (4, 9), (0, 3), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Heywood'\n",
    "# env = FigureHeywood(10, 10, (4, 4), (0, 4), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Random'\n",
    "env = FigureRandom(20, 20, memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# env.shake(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.load('f5e46ad0-c274-415c-b831-7b1893ea9694', False)\n",
    "# import random\n",
    "# # new start-goal parameter generator... might want to put this in .env file, where a new id gets generated...\n",
    "# new_start = (0, 0)\n",
    "# new_goal = (0, 0)\n",
    "\n",
    "# while new_start == (0, 0) or new_start in env.illegal_states:\n",
    "#     new_start = (random.randint(0, env.rows-1), random.randint(0, env.cols-1))\n",
    "\n",
    "# while new_goal == (0, 0) or new_goal in env.illegal_states:\n",
    "#     new_goal = (random.randint(0, env.rows-1), random.randint(0, env.cols-1))\n",
    "\n",
    "# print(f'New start: {new_start}')\n",
    "# print(f'New goal: {new_goal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading env...\n",
      "Env loaded successfully!\n",
      "Rows: 20\n",
      "Columns: 20\n",
      "Start State: (17, 4)\n",
      "Win State: (5, 8)\n",
      "Illegal States: [(14, 4), (15, 18), (3, 3), (18, 2), (6, 11), (6, 4), (10, 6), (19, 10), (5, 2), (3, 4), (4, 1), (2, 10), (4, 10), (15, 2), (12, 13), (6, 15), (13, 4), (6, 8), (9, 6), (16, 10), (19, 5), (19, 2), (16, 0), (15, 8), (7, 11), (18, 5), (19, 12), (0, 17), (15, 19), (18, 19), (0, 18), (6, 1), (18, 4), (9, 18), (17, 15), (2, 6), (5, 1), (8, 18), (18, 12), (15, 4), (4, 2), (11, 5), (2, 3), (3, 19), (0, 11), (2, 18), (13, 18), (12, 6), (18, 17), (12, 5), (14, 17), (19, 9), (10, 18), (1, 4), (10, 13), (5, 19), (5, 3), (6, 18), (11, 10), (12, 3), (7, 14), (0, 7), (0, 8), (7, 0), (9, 5), (8, 7), (0, 6), (17, 3), (19, 4), (12, 12), (15, 14), (18, 11), (9, 16), (18, 0), (3, 16), (9, 3), (10, 17), (10, 15), (2, 1), (2, 2)]\n",
      "matlab code, converted so plus one to everything\n",
      "GW.CurrentState = '[3,5]';\n",
      "GW.TerminalStates = '[15,9]';\n",
      "GW.ObstacleStates = [\"[6,5]\";\"[5,19]\";\"[17,4]\";\"[2,3]\";\"[14,12]\";\"[14,5]\";\"[10,7]\";\"[1,11]\";\"[15,3]\";\"[17,5]\";\"[16,2]\";\"[18,11]\";\"[16,11]\";\"[5,3]\";\"[8,14]\";\"[14,16]\";\"[7,5]\";\"[14,9]\";\"[11,7]\";\"[4,11]\";\"[1,6]\";\"[1,3]\";\"[4,1]\";\"[5,9]\";\"[13,12]\";\"[2,6]\";\"[1,13]\";\"[20,18]\";\"[5,20]\";\"[2,20]\";\"[20,19]\";\"[14,2]\";\"[2,5]\";\"[11,19]\";\"[3,16]\";\"[18,7]\";\"[15,2]\";\"[12,19]\";\"[2,13]\";\"[5,5]\";\"[16,3]\";\"[9,6]\";\"[18,4]\";\"[17,20]\";\"[20,12]\";\"[18,19]\";\"[7,19]\";\"[8,7]\";\"[2,18]\";\"[8,6]\";\"[6,18]\";\"[1,10]\";\"[10,19]\";\"[19,5]\";\"[10,14]\";\"[15,20]\";\"[15,4]\";\"[14,19]\";\"[9,11]\";\"[8,4]\";\"[13,15]\";\"[20,8]\";\"[20,9]\";\"[13,1]\";\"[11,6]\";\"[12,8]\";\"[20,7]\";\"[3,4]\";\"[1,5]\";\"[8,13]\";\"[5,15]\";\"[2,12]\";\"[11,17]\";\"[2,1]\";\"[17,17]\";\"[11,4]\";\"[10,18]\";\"[10,16]\";\"[18,2]\";\"[18,3]\";];\n",
      "(5, 8)\n",
      "_ _ X _ X X _ _ _ X X _ X _ _ _ _ _ _ _ \n",
      "\n",
      "X _ X _ X X _ _ _ _ _ X X _ _ _ _ X _ X \n",
      "\n",
      "_ _ _ X S _ _ _ _ _ _ _ _ _ _ X _ _ _ _ \n",
      "\n",
      "X _ _ _ _ _ _ _ _ _ X _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ X _ X _ _ _ X _ _ _ _ _ X _ _ _ X X \n",
      "\n",
      "_ _ _ _ X _ _ _ _ _ _ _ _ _ _ _ _ X _ _ \n",
      "\n",
      "_ _ _ _ X _ _ _ _ _ _ _ _ _ _ _ _ _ X _ \n",
      "\n",
      "_ _ _ X _ X X _ _ _ _ _ X X _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ X _ _ _ _ X _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ X _ _ _ _ _ _ X _ X _ X X _ \n",
      "\n",
      "_ _ _ X _ X X _ _ _ _ _ _ _ _ _ X _ X _ \n",
      "\n",
      "_ _ _ _ _ _ _ X _ _ _ _ _ _ _ _ _ _ X _ \n",
      "\n",
      "X _ _ _ _ _ _ _ _ _ _ X _ _ X _ _ _ _ _ \n",
      "\n",
      "_ X _ _ X _ _ _ X _ _ X _ _ _ X _ _ X _ \n",
      "\n",
      "_ X X X _ _ _ _ W _ _ _ _ _ _ _ _ _ _ X \n",
      "\n",
      "_ X X _ _ _ _ _ _ _ X _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ X X _ _ _ _ _ _ _ _ _ _ _ X _ _ X \n",
      "\n",
      "_ X X X _ _ X _ _ _ X _ _ _ _ _ _ _ X _ \n",
      "\n",
      "_ _ _ _ X _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ X X X _ _ X _ _ _ _ _ X X _ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# envName = ''\n",
    "plotName = '202011'\n",
    "envName = '20x20#1sg#1'\n",
    "save = True\n",
    "load = False\n",
    "numGens = 200\n",
    "maxTeamPool = 5\n",
    "runs = 30\n",
    "# 20x20 #1\n",
    "# start-goal #1 for 20x20 #1 --> default load\n",
    "if envName == '20x20#1sg#1':\n",
    "    env.load('592726fe-a9e1-46fc-99c3-fc97ffeb4b51')\n",
    "# start-goal #2 for 20x20 #1\n",
    "elif envName == '20x20#1sg#2':\n",
    "    env.load('592726fe-a9e1-46fc-99c3-fc97ffeb4b51', False)\n",
    "    env.start_state = (15, 15)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (3, 8)\n",
    "    env.display()\n",
    "# start-goal #3 for 20x20 #2\n",
    "elif envName == '20x20#1sg#3':\n",
    "    env.load('592726fe-a9e1-46fc-99c3-fc97ffeb4b51', False)\n",
    "    env.start_state = (12, 19)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (9, 13)\n",
    "    env.display()\n",
    "elif envName == '20x20#1sg#4':\n",
    "    env.load('592726fe-a9e1-46fc-99c3-fc97ffeb4b51', False)\n",
    "    env.start_state = (15, 17)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (0, 15)\n",
    "    env.display()\n",
    "elif envName == '20x20#1sg#5':\n",
    "    env.load('592726fe-a9e1-46fc-99c3-fc97ffeb4b51', False)\n",
    "    env.start_state = (15, 11)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (10, 7)\n",
    "    env.display()\n",
    "elif envName == '20x20#2sg#1':\n",
    "    env.load('00840a8c-af04-4a3e-b427-451ab41f3301')\n",
    "elif envName == '20x20#2sg#2':\n",
    "    env.load('00840a8c-af04-4a3e-b427-451ab41f3301', False)\n",
    "    env.start_state = (10, 2)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (6, 18)\n",
    "    env.display()\n",
    "elif envName == '20x20#2sg#3':\n",
    "    env.load('00840a8c-af04-4a3e-b427-451ab41f3301', False)\n",
    "    env.start_state = (0, 15)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (14, 0)\n",
    "    env.display()\n",
    "elif envName == '20x20#2sg#4':\n",
    "    env.load('00840a8c-af04-4a3e-b427-451ab41f3301', False)\n",
    "    env.start_state = (9, 4)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (15, 0)\n",
    "    env.display()\n",
    "elif envName == '20x20#2sg#5':\n",
    "    env.load('00840a8c-af04-4a3e-b427-451ab41f3301', False)\n",
    "    env.start_state = (14, 16)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (8, 5)\n",
    "    env.display()\n",
    "elif envName == '20x20#3sg#1':\n",
    "    env.load('2ca23d5d-788e-44df-9ca1-96b18b9c223f')\n",
    "elif envName == '20x20#3sg#2':\n",
    "    env.load('2ca23d5d-788e-44df-9ca1-96b18b9c223f', False)\n",
    "    env.start_state = (7, 9)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (17, 10)\n",
    "    env.display()\n",
    "elif envName == '20x20#3sg#3':\n",
    "    env.load('2ca23d5d-788e-44df-9ca1-96b18b9c223f', False)\n",
    "    env.start_state = (3, 2)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (0, 14)\n",
    "    env.display()\n",
    "elif envName == '20x20#3sg#4':\n",
    "    env.load('2ca23d5d-788e-44df-9ca1-96b18b9c223f', False)\n",
    "    env.start_state = (0, 13)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (15, 18)\n",
    "    env.display()\n",
    "elif envName == '20x20#3sg#5':\n",
    "    env.load('2ca23d5d-788e-44df-9ca1-96b18b9c223f', False)\n",
    "    env.start_state = (1, 8)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (3, 14)\n",
    "    env.display()\n",
    "# 50x50s\n",
    "elif envName == '50x50#1sg#1':\n",
    "    env.load('f5e46ad0-c274-415c-b831-7b1893ea9694')\n",
    "elif envName == '50x50#1sg#2':\n",
    "    env.load('f5e46ad0-c274-415c-b831-7b1893ea9694', False)\n",
    "    env.start_state = (16, 46)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (20, 1)\n",
    "    env.display()\n",
    "elif envName == '50x50#1sg#3':\n",
    "    env.load('f5e46ad0-c274-415c-b831-7b1893ea9694', False)\n",
    "    env.start_state = (3, 12)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (14, 43)\n",
    "    env.display()\n",
    "elif envName == '50x50#1sg#4':\n",
    "    env.load('f5e46ad0-c274-415c-b831-7b1893ea9694', False)\n",
    "    env.start_state = (37, 17)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (20, 46)\n",
    "    env.display()\n",
    "elif envName == '50x50#1sg#5':\n",
    "    env.load('f5e46ad0-c274-415c-b831-7b1893ea9694', False)\n",
    "    env.start_state = (20, 11)\n",
    "    env.current_state = env.start_state\n",
    "    env.win_state = (42, 25)\n",
    "    env.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init search manager and starting teams\n",
    "\n",
    "# searchManager = SearchManager(maxTeamPool)\n",
    "\n",
    "# variables for tracking fitness, for curves\n",
    "scores = []\n",
    "gens = []\n",
    "maxes = []\n",
    "averages = []\n",
    "mins = []\n",
    "\n",
    "run_winners = []\n",
    "runs_score_track = []\n",
    "\n",
    "for run in range(runs):\n",
    "    gp_query_env = 0\n",
    "    maxes = []\n",
    "    averages = []\n",
    "    mins = []\n",
    "    gens = []\n",
    "    print(run)\n",
    "    # init everything for new run\n",
    "    searchManager = SearchManager(maxTeamPool)\n",
    "    \n",
    "    adam_and_eve = []\n",
    "    env.reset()\n",
    "    init_team = Team(uuid.uuid4(), 0, 0, 1, 1, 0)\n",
    "    init_team.init_search(env, [2, 3])\n",
    "#     adam_and_eve.append(init_team)\n",
    "#     init_team = Team(uuid.uuid4(), 0, 0, 1, 1, 0)\n",
    "#     init_team.init_search(env, [0, 1])\n",
    "    adam_and_eve.append(init_team)\n",
    "    win = False\n",
    "    for adam in adam_and_eve:\n",
    "        data = [adam, win]\n",
    "        searchManager.evaluate_team(data)\n",
    "    \n",
    "    \n",
    "    average_coverage = 0.0\n",
    "    gen = 0\n",
    "    for gen in range(numGens):\n",
    "#     while (average_coverage < 0.4) and (len(searchManager.winners) < maxTeamPool):\n",
    "#         print(average_coverage)\n",
    "#         print('winners so far:')\n",
    "#         print(searchManager.winners)\n",
    "        print(f'GEN --> {gen}')\n",
    "        gen += 1\n",
    "        toEvaluateAfterGen = []\n",
    "        scores = []\n",
    "        # get it started\n",
    "        for parent in searchManager.teamPool:\n",
    "            # only run if the team has not yet won\n",
    "            if parent not in searchManager.winners:\n",
    "                env.current_state = parent.start_state\n",
    "\n",
    "                # make offspring from parent, then let that offspring make a new rule\n",
    "                child = copy.deepcopy(parent)\n",
    "\n",
    "                child.gp_query_env = parent.gp_query_env # probably don't need this, can test later\n",
    "                child.id = uuid.uuid4()\n",
    "                child.gen_created = gen\n",
    "                win = child.search_no_back_track(env)\n",
    "                \n",
    "                if child.mostRecent.program.rule.region[3] - child.mostRecent.program.rule.region[2] >= 0:\n",
    "                    gp_query_env += (child.mostRecent.program.rule.region[3] - child.mostRecent.program.rule.region[2]) + 1\n",
    "                \n",
    "                toEvaluateAfterGen.append([child, win])\n",
    "                scores.append(child)\n",
    "            else:\n",
    "                scores.append(parent)\n",
    "\n",
    "        for data in toEvaluateAfterGen:\n",
    "            searchManager.evaluate_team(data)\n",
    "        # start: manage fitness curves (at end of gen)\n",
    "        gens.append(gen)\n",
    "        total = 0\n",
    "        max_fitness = -100\n",
    "        min_fitness = 100\n",
    "\n",
    "        for team in scores:\n",
    "            total += team.fitness\n",
    "            if team.fitness > max_fitness:\n",
    "                max_fitness = team.fitness\n",
    "            if team.fitness < min_fitness:\n",
    "                min_fitness = team.fitness\n",
    "        average_fitness = total / len(searchManager.teamPool)\n",
    "        maxes.append(max_fitness)\n",
    "        averages.append(average_fitness)\n",
    "        mins.append(min_fitness)\n",
    "        \n",
    "        # find average region coverage\n",
    "        total_coverage = 0.0\n",
    "        for team in searchManager.teamPool:\n",
    "            total_coverage += team.coverage([env.rows, env.cols], env.illegal_states)\n",
    "        average_coverage = total_coverage / len(searchManager.teamPool)\n",
    "\n",
    "    runs_score_track.append({'run': run, 'maxes': maxes, 'averages': averages, 'mins': mins})\n",
    "    \n",
    "    run_winners.append({'run': run, 'winners': searchManager.winners})\n",
    "    gp_query_runs.append(gp_query_env)\n",
    "    print(gp_query_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitness curves\n",
    "# x = []\n",
    "# y = []\n",
    "# for gen in gens:\n",
    "#     x.append(gen)\n",
    "\n",
    "# for average in averages:\n",
    "#     y.append(average)\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Average Score')\n",
    "# plt.plot(x, y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fitness curves\n",
    "# x = []\n",
    "# y = []\n",
    "# for gen in gens:\n",
    "#     x.append(gen)\n",
    "\n",
    "# for max_ in maxes:\n",
    "#     y.append(max_)\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Max Score')\n",
    "# plt.plot(x, y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for team in searchManager.winners:\n",
    "#     print('$$$$$$$$$$$$$ winnnnnner start $$$$$$$$$$$$$$$$$$$$')\n",
    "#     print(team.fitness)\n",
    "#     print('Learners:')\n",
    "#     for learner in team.learners:\n",
    "#         print(f'Region: {learner.program.rule.region} --> Action: {learner.program.rule.action_set}')\n",
    "#     print('$$$$$$$$$$$$$ winnnnnner end $$$$$$$$$$$$$$$$$$$$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for team in searchManager.winners:\n",
    "\n",
    "    region_action_scores = []\n",
    "    for learner in team.learners:\n",
    "        if learner.program.rule.value_set[0] > learner.program.rule.value_set[1]:\n",
    "            region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[0], 'q': learner.program.rule.value_set[0]})\n",
    "        else:\n",
    "            region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[1], 'q': learner.program.rule.value_set[1]})\n",
    "\n",
    "    sorted_region_action_scores = sorted(region_action_scores, key=lambda value: float(value['q']), reverse=True)\n",
    "    # print(sorted_region_action_scores)\n",
    "    # for record in sorted_region_action_scores:\n",
    "    #     print(record)\n",
    "    action_states = []\n",
    "    for record in sorted_region_action_scores:\n",
    "        action = ''\n",
    "        if record['action'] == 0:\n",
    "            action = '\\u2191'\n",
    "        elif record['action'] == 1:\n",
    "            action = '\\u2193'\n",
    "        elif record['action'] == 2:\n",
    "            action = '\\u2192'\n",
    "        elif record['action'] == 3:\n",
    "            action = '\\u2190'\n",
    "\n",
    "        for i in range(record['region'][3] - record['region'][2]+1):\n",
    "            state = [0, 0]\n",
    "            state[record['region'][0]] = record['region'][1]\n",
    "            state[not record['region'][0]] = record['region'][2] + i\n",
    "\n",
    "            # ensure we do not enter duplicate states\n",
    "            found = 0\n",
    "            for pair in action_states:\n",
    "                if pair['state'] == (state[0], state[1]):\n",
    "                    found = 1\n",
    "\n",
    "            if found == 0:\n",
    "                action_states.append({'state': (state[0], state[1]), 'action': action, 'q': record['q'] })\n",
    "\n",
    "    # add in the rest of the states, either they are not visited, or illegal\n",
    "#     for n in reversed(range(env.rows)):\n",
    "#         for m in range(env.cols):\n",
    "#             action = ''\n",
    "#             found = 0\n",
    "#             for record in action_states:\n",
    "#                 if record['state'] == (n, m):\n",
    "#                     found = 1\n",
    "#                     action = record['action']\n",
    "#     #                 action = float(round(record['q'], 0))\n",
    "#             if found == 0:\n",
    "#                 if not env.check_legal((n, m)):\n",
    "#                     action = 'X'\n",
    "#                 else:\n",
    "#                     action = '?'\n",
    "#             print(f'{action} ', end='')\n",
    "#         print('\\n')\n",
    "#     print('------------NEW WINNER ----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Max Fitness Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_run = 0\n",
    "\n",
    "print(runs_score_track[selected_run]['maxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fitness curves\n",
    "x = []\n",
    "y = []\n",
    "average_maxes = np.zeros(numGens)\n",
    "# average_maxes = np.zeros(100)\n",
    "\n",
    "for i in range(len(gens)):\n",
    "    for q in range(len(runs_score_track)):\n",
    "        average_maxes[i] += runs_score_track[q]['maxes'][i]\n",
    "    average_maxes[i] /= len(runs_score_track)\n",
    "    \n",
    "for gen in gens:\n",
    "    x.append(gen)\n",
    "\n",
    "# plt.title(f'Average max score over {len(runs_score_track)} runs for {envName}')\n",
    "plt.title(f'Average max score over {len(runs_score_track)} runs')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Average Max Score')\n",
    "plt.plot(x, average_maxes)\n",
    "\n",
    "plt.savefig(f'qtpg/fitness_curves/{plotName}.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning + Victory Lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load == True:\n",
    "    runs = 30\n",
    "    resultsManager = ResultsManager()\n",
    "    run_winners, loadedQueryTotals, win_loss = resultsManager.load_champions(envName)\n",
    "    print(loadedQueryTotals)\n",
    "    run_count = 0\n",
    "    for run in range(runs):\n",
    "        if (run_count >= len(run_winners)):\n",
    "            run_winners.append({'run': run_count, 'winners': []})\n",
    "        elif run_winners[run]['run'] != run_count:\n",
    "            run_winners.insert(run_count, {'run': run_count, 'winners': []})\n",
    "        run_count += 1\n",
    "    for run in run_winners:\n",
    "    #     print(run)\n",
    "        for champ in run['winners']:\n",
    "            print(champ.id)\n",
    "else:\n",
    "    print('not loading!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# team = searchManager.winners[0]\n",
    "win_loss = []\n",
    "\n",
    "total_count = 0\n",
    "fail_count = 0\n",
    "# team = run_winners[0]['winners'][0]\n",
    "stuck_count = 0\n",
    "switch_count = 0\n",
    "agent_failed = 0\n",
    "for run in range(runs):\n",
    "    for team in run_winners[run]['winners']:\n",
    "        total_count += 1\n",
    "        stuck_count = 0\n",
    "        switch_count = 0\n",
    "        print('NEW CHAMPION!')\n",
    "        print(f'Run: {run}')\n",
    "        print(f'Winner: {team.id}')\n",
    "        team.discount = 0.9\n",
    "        team.alpha = 0.5\n",
    "        # for learner in team.learners:\n",
    "        #     print(learner.program.rule.region)\n",
    "\n",
    "        # team.prune_single_cell_regions() # don't think this is good...\n",
    "        team.prune_duplicate_regions()\n",
    "        print('pruned!')\n",
    "        # illegal_states = [(2, 0), (2, 1), (3, 1), (1, 3), (2, 3), (3, 3), (1, 4)]\n",
    "        illegal_states = env.illegal_states\n",
    "        dimensions = [env.rows, env.cols]\n",
    "\n",
    "#         print(env.start_state)\n",
    "#         print(env.win_state)\n",
    "        for i in range(env.rows):\n",
    "            agent_failed = 0\n",
    "        #     print(f'Epoch: {i+1} --------')\n",
    "        #     env.reset()\n",
    "            switch_count = 0\n",
    "            stuck_count = 0\n",
    "            current_state = env.start_state\n",
    "#             print(f'curr -> {env.current_state}')\n",
    "            win = False\n",
    "            selected_learner = team.select_learner(current_state, [0, 0, 0, 0])\n",
    "            while not win and stuck_count < 15 and switch_count < 1000:\n",
    "#             while not win:\n",
    "        #         win, needs_update, reward, winning_action = team.q_evaluation(env, selected_learner)\n",
    "                if selected_learner is None:\n",
    "                    stuck_count += 1\n",
    "#                     print('nnone!-0')\n",
    "                else:\n",
    "                    win, needs_update, reward, winning_action, current_state = team.q_evaluation(current_state, selected_learner, illegal_states, dimensions)\n",
    "                    if reward is False:\n",
    "                        break\n",
    "                        agent_failed = 1\n",
    "                    print(current_state)\n",
    "                    if not win:\n",
    "                        selected_learner = team.select_learner(current_state, selected_learner.program.rule.region)\n",
    "                        if selected_learner is None:\n",
    "#                             print('none!?')\n",
    "                            stuck_count += 1\n",
    "                        else:\n",
    "                            team.transition_update(reward, winning_action, needs_update, selected_learner)\n",
    "                            switch_count += 1\n",
    "#                             stuck_count = 0\n",
    "            if stuck_count >= 15:\n",
    "                print('stuck fail!')\n",
    "#                 fail_count += 1\n",
    "                agent_failed = 1\n",
    "            if switch_count >= 1000:\n",
    "                print('switch fail!')\n",
    "#                 fail_count += 1\n",
    "                agent_failed = 1\n",
    "            if reward is not False:\n",
    "                team.final_update(reward, winning_action, needs_update)\n",
    "            else:\n",
    "                if agent_failed == 0:\n",
    "                    fail_count += 1\n",
    "        print(f'Win? --> {win}')\n",
    "        win_loss.append(win)\n",
    "#         for learner in team.learners:\n",
    "#             print(f'{learner.program.rule.region}')\n",
    "#             for i in range(len(learner.program.rule.action_set)):\n",
    "#                   print(f'{learner.program.rule.action_set[i]} --> {learner.program.rule.value_set[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save == True:\n",
    "    resultsManager = ResultsManager()\n",
    "    resultsManager.save_champions(envName, run_winners, gp_query_runs, win_loss)\n",
    "else:\n",
    "    print('not saving!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Action Map (RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superimpose = []\n",
    "for n in reversed(range(env.rows)):\n",
    "    for m in range(env.cols):\n",
    "        superimpose.append({ 'state': (n, m), 'action_count': [0, 0, 0, 0] })\n",
    "\n",
    "# for state in superimpose:\n",
    "#     print(state)\n",
    "    \n",
    "for state in superimpose:\n",
    "    if state['state'] == (50, 2):\n",
    "        print('yeah!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for run in range(runs):\n",
    "    for team in run_winners[run]['winners']:\n",
    "\n",
    "        print(f'Run: {run}')\n",
    "        print(f'Team: {team.id}')\n",
    "        \n",
    "        region_action_scores = []\n",
    "        for learner in team.learners:\n",
    "            if learner.program.rule.value_set[0] > learner.program.rule.value_set[1]:\n",
    "                region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[0], 'q': learner.program.rule.value_set[0]})\n",
    "            else:\n",
    "                region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[1], 'q': learner.program.rule.value_set[1]})\n",
    "\n",
    "        sorted_region_action_scores = sorted(region_action_scores, key=lambda value: float(value['q']), reverse=True)\n",
    "        # print(sorted_region_action_scores)\n",
    "        # for record in sorted_region_action_scores:\n",
    "        #     print(record)\n",
    "        action_states = []\n",
    "        for record in sorted_region_action_scores:\n",
    "            action = ''\n",
    "            if record['action'] == 0:\n",
    "                action = '\\u2191'\n",
    "            elif record['action'] == 1:\n",
    "                action = '\\u2193'\n",
    "            elif record['action'] == 2:\n",
    "                action = '\\u2192'\n",
    "            elif record['action'] == 3:\n",
    "                action = '\\u2190'\n",
    "\n",
    "            for i in range(record['region'][3] - record['region'][2]+1):\n",
    "                state = [0, 0]\n",
    "                state[record['region'][0]] = record['region'][1]\n",
    "                state[not record['region'][0]] = record['region'][2] + i\n",
    "                for cumulative in superimpose:\n",
    "                    if cumulative['state'] == (state[0], state[1]):\n",
    "                        if action == '\\u2191':\n",
    "                            cumulative['action_count'][0] += record['q']\n",
    "                        elif action == '\\u2193':\n",
    "                            cumulative['action_count'][1] += record['q']\n",
    "                        elif action == '\\u2192':\n",
    "                            cumulative['action_count'][2] += record['q']\n",
    "                        elif action == '\\u2190':\n",
    "                            cumulative['action_count'][3] += record['q']\n",
    "                \n",
    "                # ensure we do not enter duplicate states\n",
    "                found = 0\n",
    "                for pair in action_states:\n",
    "                    if pair['state'] == (state[0], state[1]):\n",
    "                        found = 1\n",
    "\n",
    "                if found == 0:\n",
    "                    action_states.append({'state': (state[0], state[1]), 'action': action, 'q': record['q'] })\n",
    "\n",
    "        # add in the rest of the states, either they are not visited, or illegal\n",
    "        for n in reversed(range(env.rows)):\n",
    "            for m in range(env.cols):\n",
    "                action = ''\n",
    "                found = 0\n",
    "                for record in action_states:\n",
    "                    if record['state'] == (n, m):\n",
    "                        found = 1\n",
    "                        action = record['action']\n",
    "        #                 action = float(round(record['q'], 0))\n",
    "                if found == 0:\n",
    "                    if not env.check_legal((n, m)):\n",
    "                        action = 'X'\n",
    "                    else:\n",
    "                        action = '?'\n",
    "                if (n, m) == env.start_state:\n",
    "                    action = 'S'\n",
    "                if (n, m) == env.win_state:\n",
    "                    action = 'G'\n",
    "                print(f'{action} ', end='')\n",
    "            print('\\n')\n",
    "\n",
    "        q_map = np.zeros((env.rows, env.cols))\n",
    "\n",
    "        # add in the rest of the states, either they are not visited, or illegal\n",
    "        for n in range(env.rows):\n",
    "            for m in range(env.cols):\n",
    "                action = ''\n",
    "                found = 0\n",
    "                for record in action_states:\n",
    "                    if record['state'] == (n, m):\n",
    "                        found = 1\n",
    "                        action = record['q']\n",
    "                if found == 0:\n",
    "                    if not env.check_legal((n, m)):\n",
    "                        action = -1\n",
    "                    else:\n",
    "                        action = 0\n",
    "                q_map[(env.rows-1)-n][m] = action\n",
    "\n",
    "        plt.imshow(q_map, cmap='Blues', interpolation='nearest')\n",
    "        if (load == False):\n",
    "            plt.savefig(f'qtpg/qmaps/{plotName}/{team.id}_qmap.png')\n",
    "        plt.show()\n",
    "\n",
    "#         x = []\n",
    "#         y = []\n",
    "#         for i in range(env.cols):\n",
    "#             x.append(i)\n",
    "#             y.append(i)\n",
    "\n",
    "#         Y, X = np.meshgrid(x, y)\n",
    "\n",
    "#         fig = plt.figure()\n",
    "\n",
    "#         # syntax for 3-D plotting\n",
    "#         ax = plt.axes(projection ='3d')\n",
    "\n",
    "#         # syntax for plotting\n",
    "#         ax.plot_surface(X, Y, q_map, cmap ='viridis', edgecolor ='green')\n",
    "#         ax.set_title(f'Surface plot for {envName}')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "actionables = []\n",
    "\n",
    "# add in the rest of the states, either they are not visited, or illegal\n",
    "for n in reversed(range(env.rows)):\n",
    "    for m in range(env.cols):\n",
    "        action = ''\n",
    "        for record in superimpose:\n",
    "            if record['state'] == (n, m):\n",
    "                chosen_counts = 0\n",
    "                for i in range(len(record['action_count'])):\n",
    "                    if record['action_count'][i] > chosen_counts:\n",
    "                        chosen_counts = record['action_count'][i]\n",
    "                        if i == 0:\n",
    "                            action = '\\u2191'\n",
    "                        elif i == 1:\n",
    "                            action = '\\u2193'\n",
    "                        elif i == 2:\n",
    "                            action = '\\u2192'\n",
    "                        elif i == 3:\n",
    "                            action = '\\u2190'\n",
    "                    if chosen_counts == 0:\n",
    "                        action = '?'\n",
    "                    if not env.check_legal((n, m)):\n",
    "                        action = 'X'\n",
    "#                     if (n, m) == env.start_state:\n",
    "#                         action = 'S'\n",
    "                    if (n, m) == env.win_state:\n",
    "                        action = 'G'\n",
    "                if action != '?' and action != 'X' and action != 'G':\n",
    "                    actionables.append({ 'state': (n, m), 'action': action, 'win': False })\n",
    "                elif action == 'G':\n",
    "                    actionables.append({ 'state': (n, m), 'action': action, 'win': True })\n",
    "        \n",
    "        if (n, m) == env.start_state:\n",
    "            print('S ', end='')\n",
    "        else:\n",
    "            print(f'{action} ', end='')\n",
    "    print('\\n')\n",
    "\n",
    "states = []\n",
    "for actionable in actionables:\n",
    "    states.append(actionable['state'])\n",
    "    \n",
    "win_count = 0\n",
    "for actionable in actionables:\n",
    "    cancel = 0\n",
    "    memory = []\n",
    "    start = actionable['state']\n",
    "    curr = actionable\n",
    "    while cancel == 0:\n",
    "        if curr['action'] == '\\u2191':\n",
    "            state = (curr['state'][0]+1, curr['state'][1])\n",
    "        elif curr['action'] == '\\u2193':\n",
    "            state = (curr['state'][0]-1, curr['state'][1])\n",
    "        elif curr['action'] == '\\u2192':\n",
    "            state = (curr['state'][0], curr['state'][1]+1)\n",
    "        elif curr['action'] == '\\u2190':\n",
    "            state = (curr['state'][0], curr['state'][1]-1)\n",
    "\n",
    "        if state in memory:\n",
    "            cancel = 1\n",
    "        else:\n",
    "            memory.append(state)\n",
    "        \n",
    "        if state == env.win_state:\n",
    "            win_count += 1\n",
    "            cancel = 1\n",
    "    \n",
    "        found = 0\n",
    "        for actionable in actionables:\n",
    "            if state == actionable['state']:\n",
    "                curr = actionable\n",
    "                found = 1\n",
    "        if found == 0:\n",
    "            cancel = 1\n",
    "\n",
    "print(f'number of actionable cells: {len(actionables)}')\n",
    "print(f'number of actionable cells that lead to goal: {win_count}')\n",
    "print(f'% of actionable cells that lead to goal overall: {win_count / len(actionables) * 100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap (RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for run in range(runs):\n",
    "#     for team in run_winners[run]['winners']:\n",
    "\n",
    "#         print(f'Run: {run}')\n",
    "#         print(f'Team: {team.id}')\n",
    "        \n",
    "#         region_action_scores = []\n",
    "#         for learner in team.learners:\n",
    "#             if learner.program.rule.value_set[0] > learner.program.rule.value_set[1]:\n",
    "#                 region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[0], 'q': learner.program.rule.value_set[0]})\n",
    "#             else:\n",
    "#                 region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[1], 'q': learner.program.rule.value_set[1]})\n",
    "\n",
    "#         sorted_region_action_scores = sorted(region_action_scores, key=lambda value: float(value['q']), reverse=True)\n",
    "\n",
    "#         state_counts = []\n",
    "\n",
    "#         for n in reversed(range(env.rows)):\n",
    "#             for m in range(env.cols):\n",
    "#                 state_count = 0\n",
    "#                 for record in sorted_region_action_scores:\n",
    "#                     for i in range(record['region'][3] - record['region'][2]+1):\n",
    "#                         state = [0, 0]\n",
    "#                         state[record['region'][0]] = record['region'][1]\n",
    "#                         state[not record['region'][0]] = record['region'][2] + i\n",
    "\n",
    "#                         if state == [n, m]:\n",
    "#                             state_count += 1\n",
    "#                         # state count logic goes here\n",
    "#                 state_counts.append({'state': (n, m), 'count': state_count})\n",
    "\n",
    "#         for n in reversed(range(env.rows)):\n",
    "#             for m in range(env.cols):\n",
    "#                 for record in state_counts:\n",
    "#                     if (n, m) == record['state']:\n",
    "#                         count = record['count']\n",
    "#                         print(f'{count} ', end='')\n",
    "#             print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_average = 0\n",
    "if load == False:\n",
    "    for query_total in gp_query_runs:\n",
    "        query_average += query_total\n",
    "    query_average /= len(gp_query_runs)\n",
    "else:\n",
    "    for query_total in loadedQueryTotals:\n",
    "        query_average += query_total\n",
    "    query_average /= len(loadedQueryTotals)\n",
    "\n",
    "print(f'Average query total: {query_average}')\n",
    "loss_count = 0\n",
    "for attempt in win_loss:\n",
    "    if attempt == False:\n",
    "        loss_count += 1\n",
    "print(f'RL Runs: {len(win_loss)}')\n",
    "print(f'Loss Count: {loss_count}')\n",
    "print(f'Win Count: {len(win_loss) - loss_count}')\n",
    "print(f'Win Ratio: {(len(win_loss) - loss_count) / len(win_loss)} --> {((len(win_loss) - loss_count) / len(win_loss)) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
