{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qtpg.team import Team\n",
    "from qtpg.learner import Learner\n",
    "from qtpg.program import Program\n",
    "from qtpg.rule import Rule\n",
    "from qtpg.figure13 import Figure13\n",
    "from qtpg.figure13_hole_in_wall import Figure13HoleInWall\n",
    "from qtpg.figure12 import Figure12\n",
    "from qtpg.figure9 import Figure9\n",
    "from qtpg.figureRandom import FigureRandom\n",
    "from qtpg.figureHeywood import FigureHeywood\n",
    "from qtpg.search_manager import SearchManager\n",
    "import numpy as np\n",
    "import uuid\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_query_env = 0\n",
    "rl_query_env = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 20\n",
      "Columns: 20\n",
      "Start State: (0, 16)\n",
      "Win State: (18, 3)\n",
      "Illegal States: [(5, 10), (9, 10), (8, 18), (4, 13), (6, 15), (19, 11), (19, 10), (8, 0), (16, 6), (18, 15), (2, 11), (5, 13), (6, 11), (8, 6), (4, 9), (7, 8), (6, 8), (15, 10), (0, 18), (10, 12), (13, 11), (2, 17), (4, 8), (8, 1), (6, 4), (1, 6), (19, 0), (19, 19), (11, 12), (0, 19), (5, 5), (3, 18), (17, 11), (1, 9), (5, 14), (8, 2), (4, 0), (13, 0), (17, 8), (0, 4), (10, 19), (9, 19), (7, 17), (1, 17), (6, 2), (7, 9), (13, 2), (0, 3), (10, 11), (11, 14), (13, 17), (8, 13), (12, 4), (11, 3), (19, 8), (13, 12), (9, 9), (0, 13), (3, 6), (7, 11), (15, 6), (13, 19), (7, 1), (2, 8), (11, 1), (16, 5), (12, 15), (3, 14), (0, 7), (14, 18), (9, 4), (0, 6), (2, 15), (13, 5), (0, 12), (12, 17), (1, 13), (5, 12), (9, 15), (6, 9)]\n",
      "matlab code, converted so plus one to everything\n",
      "GW.CurrentState = '[1,17]';\n",
      "GW.TerminalStates = '[19,4]';\n",
      "GW.ObstacleStates = [\"[6,11]\";\"[10,11]\";\"[9,19]\";\"[5,14]\";\"[7,16]\";\"[20,12]\";\"[20,11]\";\"[9,1]\";\"[17,7]\";\"[19,16]\";\"[3,12]\";\"[6,14]\";\"[7,12]\";\"[9,7]\";\"[5,10]\";\"[8,9]\";\"[7,9]\";\"[16,11]\";\"[1,19]\";\"[11,13]\";\"[14,12]\";\"[3,18]\";\"[5,9]\";\"[9,2]\";\"[7,5]\";\"[2,7]\";\"[20,1]\";\"[20,20]\";\"[12,13]\";\"[1,20]\";\"[6,6]\";\"[4,19]\";\"[18,12]\";\"[2,10]\";\"[6,15]\";\"[9,3]\";\"[5,1]\";\"[14,1]\";\"[18,9]\";\"[1,5]\";\"[11,20]\";\"[10,20]\";\"[8,18]\";\"[2,18]\";\"[7,3]\";\"[8,10]\";\"[14,3]\";\"[1,4]\";\"[11,12]\";\"[12,15]\";\"[14,18]\";\"[9,14]\";\"[13,5]\";\"[12,4]\";\"[20,9]\";\"[14,13]\";\"[10,10]\";\"[1,14]\";\"[4,7]\";\"[8,12]\";\"[16,7]\";\"[14,20]\";\"[8,2]\";\"[3,9]\";\"[12,2]\";\"[17,6]\";\"[13,16]\";\"[4,15]\";\"[1,8]\";\"[15,19]\";\"[10,5]\";\"[1,7]\";\"[3,16]\";\"[14,6]\";\"[1,13]\";\"[13,18]\";\"[2,14]\";\"[6,13]\";\"[10,16]\";\"[7,10]\";];\n",
      "(18, 3)\n",
      "X _ _ _ _ _ _ _ X _ X X _ _ _ _ _ _ _ X \n",
      "\n",
      "_ _ _ W _ _ _ _ _ _ _ _ _ _ _ X _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ _ _ X _ _ X _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ X X _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ X _ _ _ X _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ X _ \n",
      "\n",
      "X _ X _ _ X _ _ _ _ _ X X _ _ _ _ X _ X \n",
      "\n",
      "_ _ _ _ X _ _ _ _ _ _ _ _ _ _ X _ X _ _ \n",
      "\n",
      "_ X _ X _ _ _ _ _ _ _ _ X _ X _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _ X X _ _ _ _ _ _ X \n",
      "\n",
      "_ _ _ _ X _ _ _ _ X X _ _ _ _ X _ _ _ X \n",
      "\n",
      "X X X _ _ _ X _ _ _ _ _ _ X _ _ _ _ X _ \n",
      "\n",
      "_ X _ _ _ _ _ _ X X _ X _ _ _ _ _ X _ _ \n",
      "\n",
      "_ _ X _ X _ _ _ X X _ X _ _ _ X _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ X _ _ _ _ X _ X X X _ _ _ _ _ \n",
      "\n",
      "X _ _ _ _ _ _ _ X X _ _ _ X _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ X _ _ _ _ _ _ _ X _ _ _ X _ \n",
      "\n",
      "_ _ _ _ _ _ _ _ X _ _ X _ _ _ X _ X _ _ \n",
      "\n",
      "_ _ _ _ _ _ X _ _ X _ _ _ X _ _ _ X _ _ \n",
      "\n",
      "_ _ _ X X _ X X _ _ _ _ X X _ _ S _ X X \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# env params\n",
    "memorySize = 40\n",
    "legalMove = 0.1\n",
    "illegalMove = -0.01\n",
    "outOfBounds = 0.0\n",
    "memoryRepeat = -0.01\n",
    "# memoryRepeat = 0.0\n",
    "goalReached = 100\n",
    "\n",
    "# envName = 'Figure 13'\n",
    "# env = Figure13(5, 5, (2, 4), (0, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Figure 13 Hole in Wall'\n",
    "# env = Figure13HoleInWall(5, 5, (2, 4), (0, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Figure 12'\n",
    "# env = Figure12(5, 5, (4, 4), (0, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Figure 9'\n",
    "# env = Figure9(10, 10, (4, 9), (0, 3), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Heywood'\n",
    "# env = FigureHeywood(10, 10, (4, 4), (0, 4), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "envName = 'Random'\n",
    "env = FigureRandom(20, 20, memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "env.shake(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.load('990993d3-bafb-40d3-89e6-27869ed77ca8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numGens = 100\n",
    "maxTeamPool = 10\n",
    "runs = 1\n",
    "# init search manager and starting teams\n",
    "\n",
    "# searchManager = SearchManager(maxTeamPool)\n",
    "\n",
    "# variables for tracking fitness, for curves\n",
    "scores = []\n",
    "gens = []\n",
    "maxes = []\n",
    "averages = []\n",
    "mins = []\n",
    "\n",
    "run_winners = []\n",
    "runs_score_track = []\n",
    "\n",
    "for run in range(runs):\n",
    "    maxes = []\n",
    "    averages = []\n",
    "    mins = []\n",
    "    gens = []\n",
    "    print(run)\n",
    "    # init everything for new run\n",
    "    searchManager = SearchManager(maxTeamPool)\n",
    "    \n",
    "    adam_and_eve = []\n",
    "    env.reset()\n",
    "    init_team = Team(uuid.uuid4(), 0, 0, 1, 1, 0)\n",
    "    init_team.init_search(env, [2, 3])\n",
    "    adam_and_eve.append(init_team)\n",
    "    init_team = Team(uuid.uuid4(), 0, 0, 1, 1, 0)\n",
    "    init_team.init_search(env, [0, 1])\n",
    "    adam_and_eve.append(init_team)\n",
    "    win = False\n",
    "    for adam in adam_and_eve:\n",
    "        data = [adam, win]\n",
    "        searchManager.evaluate_team(data)\n",
    "    \n",
    "    \n",
    "    for gen in range(numGens):\n",
    "        print('winners so far:')\n",
    "        print(searchManager.winners)\n",
    "        print(f'GEN --> {gen}')\n",
    "        toEvaluateAfterGen = []\n",
    "        scores = []\n",
    "        # get it started\n",
    "        for parent in searchManager.teamPool:\n",
    "            # only run if the team has not yet won\n",
    "            if parent not in searchManager.winners:\n",
    "                env.current_state = parent.start_state\n",
    "\n",
    "                # make offspring from parent, then let that offspring make a new rule\n",
    "                child = copy.deepcopy(parent)\n",
    "                child.gp_query_env = parent.gp_query_env # probably don't need this, can test later\n",
    "                child.id = uuid.uuid4()\n",
    "                win = child.search_no_back_track(env)\n",
    "                \n",
    "                if child.mostRecent.program.rule.region[3] - child.mostRecent.program.rule.region[2] >= 0:\n",
    "                    gp_query_env += (child.mostRecent.program.rule.region[3] - child.mostRecent.program.rule.region[2]) + 1\n",
    "                toEvaluateAfterGen.append([child, win])\n",
    "                scores.append(child)\n",
    "            else:\n",
    "                scores.append(parent)\n",
    "\n",
    "        for data in toEvaluateAfterGen:\n",
    "            searchManager.evaluate_team(data)\n",
    "        # start: manage fitness curves (at end of gen)\n",
    "        gens.append(gen)\n",
    "        total = 0\n",
    "        max_fitness = -100\n",
    "        min_fitness = 100\n",
    "\n",
    "        for team in scores:\n",
    "            total += team.fitness\n",
    "            if team.fitness > max_fitness:\n",
    "                max_fitness = team.fitness\n",
    "            if team.fitness < min_fitness:\n",
    "                min_fitness = team.fitness\n",
    "        average_fitness = total / len(searchManager.teamPool)\n",
    "        maxes.append(max_fitness)\n",
    "        averages.append(average_fitness)\n",
    "        mins.append(min_fitness)\n",
    "\n",
    "    runs_score_track.append({'run': run, 'maxes': maxes, 'averages': averages, 'mins': mins})\n",
    "    \n",
    "    run_winners.append({'run': run, 'winners': searchManager.winners})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitness curves\n",
    "# x = []\n",
    "# y = []\n",
    "# for gen in gens:\n",
    "#     x.append(gen)\n",
    "\n",
    "# for average in averages:\n",
    "#     y.append(average)\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Average Score')\n",
    "# plt.plot(x, y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fitness curves\n",
    "# x = []\n",
    "# y = []\n",
    "# for gen in gens:\n",
    "#     x.append(gen)\n",
    "\n",
    "# for max_ in maxes:\n",
    "#     y.append(max_)\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Max Score')\n",
    "# plt.plot(x, y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for team in searchManager.winners:\n",
    "    print('$$$$$$$$$$$$$ winnnnnner start $$$$$$$$$$$$$$$$$$$$')\n",
    "    print(team.fitness)\n",
    "    print('Learners:')\n",
    "    for learner in team.learners:\n",
    "        print(f'Region: {learner.program.rule.region} --> Action: {learner.program.rule.action_set}')\n",
    "    print('$$$$$$$$$$$$$ winnnnnner end $$$$$$$$$$$$$$$$$$$$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for team in searchManager.winners:\n",
    "    # importing libraries\n",
    "    from mpl_toolkits import mplot3d\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    region_action_scores = []\n",
    "    for learner in team.learners:\n",
    "        if learner.program.rule.value_set[0] > learner.program.rule.value_set[1]:\n",
    "            region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[0], 'q': learner.program.rule.value_set[0]})\n",
    "        else:\n",
    "            region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[1], 'q': learner.program.rule.value_set[1]})\n",
    "\n",
    "    sorted_region_action_scores = sorted(region_action_scores, key=lambda value: float(value['q']), reverse=True)\n",
    "    # print(sorted_region_action_scores)\n",
    "    # for record in sorted_region_action_scores:\n",
    "    #     print(record)\n",
    "    action_states = []\n",
    "    for record in sorted_region_action_scores:\n",
    "        action = ''\n",
    "        if record['action'] == 0:\n",
    "            action = '\\u2191'\n",
    "        elif record['action'] == 1:\n",
    "            action = '\\u2193'\n",
    "        elif record['action'] == 2:\n",
    "            action = '\\u2192'\n",
    "        elif record['action'] == 3:\n",
    "            action = '\\u2190'\n",
    "\n",
    "        for i in range(record['region'][3] - record['region'][2]+1):\n",
    "            state = [0, 0]\n",
    "            state[record['region'][0]] = record['region'][1]\n",
    "            state[not record['region'][0]] = record['region'][2] + i\n",
    "\n",
    "            # ensure we do not enter duplicate states\n",
    "            found = 0\n",
    "            for pair in action_states:\n",
    "                if pair['state'] == (state[0], state[1]):\n",
    "                    found = 1\n",
    "\n",
    "            if found == 0:\n",
    "                action_states.append({'state': (state[0], state[1]), 'action': action, 'q': record['q'] })\n",
    "\n",
    "    # add in the rest of the states, either they are not visited, or illegal\n",
    "    for n in reversed(range(env.rows)):\n",
    "        for m in range(env.cols):\n",
    "            action = ''\n",
    "            found = 0\n",
    "            for record in action_states:\n",
    "                if record['state'] == (n, m):\n",
    "                    found = 1\n",
    "                    action = record['action']\n",
    "    #                 action = float(round(record['q'], 0))\n",
    "            if found == 0:\n",
    "                if not env.check_legal((n, m)):\n",
    "                    action = 'X'\n",
    "                else:\n",
    "                    action = '?'\n",
    "            print(f'{action} ', end='')\n",
    "        print('\\n')\n",
    "    print('------------NEW WINNER ----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Max Fitness Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(runs_score_track[0]['maxes'][0])\n",
    "print(len(runs_score_track))\n",
    "print(len(runs_score_track[0]))\n",
    "print(len(runs_score_track[0]['maxes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitness curves\n",
    "x = []\n",
    "y = []\n",
    "average_maxes = np.zeros(numGens)\n",
    "# average_maxes = np.zeros(100)\n",
    "\n",
    "for i in range(len(gens)):\n",
    "    for q in range(len(runs_score_track)):\n",
    "        average_maxes[i] += runs_score_track[q]['maxes'][i]\n",
    "    average_maxes[i] /= len(runs_score_track)\n",
    "    \n",
    "for gen in gens:\n",
    "    x.append(gen)\n",
    "\n",
    "plt.title(f'Average max score over {len(runs_score_track)} runs for {envName}')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Average Max Score')\n",
    "plt.plot(x, average_maxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning + Victory Lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(run_winners)\n",
    "for winner in run_winners[0]['winners']:\n",
    "    for learner in winner.learners:\n",
    "        print(learner.program.rule.region)\n",
    "    print('\\n\\n\\n')\n",
    "# for learner in team.learners:\n",
    "#     print(learner.program.rule.region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(run_winners[0]['winners'])):\n",
    "    for learner in run_winners[0]['winners'][i].learners:\n",
    "        print(learner.id)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# team = searchManager.winners[0]\n",
    "team = run_winners[0]['winners'][0]\n",
    "team.discount = 0.9\n",
    "team.alpha = 0.5\n",
    "# for learner in team.learners:\n",
    "#     print(learner.program.rule.region)\n",
    "\n",
    "# team.prune_single_cell_regions() # don't think this is good...\n",
    "team.prune_duplicate_regions()\n",
    "\n",
    "for i in range(env.rows):\n",
    "#     print(f'Epoch: {i+1} --------')\n",
    "    env.reset()\n",
    "#     print(f'curr -> {env.current_state}')\n",
    "    win = False\n",
    "    selected_learner = team.select_learner(env, [0, 0, 0, 0])\n",
    "    while not win:\n",
    "        win, needs_update, reward, winning_action = team.q_evaluation(env, selected_learner)\n",
    "#         print(reward)\n",
    "#         print('hi')\n",
    "        if not win:\n",
    "            selected_learner = team.select_learner(env, selected_learner.program.rule.region)\n",
    "            team.transition_update(reward, winning_action, needs_update, selected_learner)\n",
    "            rl_query_env += 1\n",
    "\n",
    "    team.final_update(reward, winning_action, needs_update)\n",
    "\n",
    "print(win)\n",
    "for learner in team.learners:\n",
    "    print(f'{learner.program.rule.region}')\n",
    "    for i in range(len(learner.program.rule.action_set)):\n",
    "          print(f'{learner.program.rule.action_set[i]} --> {learner.program.rule.value_set[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Action Map (RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "region_action_scores = []\n",
    "for learner in team.learners:\n",
    "    if learner.program.rule.value_set[0] > learner.program.rule.value_set[1]:\n",
    "        region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[0], 'q': learner.program.rule.value_set[0]})\n",
    "    else:\n",
    "        region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[1], 'q': learner.program.rule.value_set[1]})\n",
    "\n",
    "sorted_region_action_scores = sorted(region_action_scores, key=lambda value: float(value['q']), reverse=True)\n",
    "# print(sorted_region_action_scores)\n",
    "# for record in sorted_region_action_scores:\n",
    "#     print(record)\n",
    "action_states = []\n",
    "for record in sorted_region_action_scores:\n",
    "    action = ''\n",
    "    if record['action'] == 0:\n",
    "        action = '\\u2191'\n",
    "    elif record['action'] == 1:\n",
    "        action = '\\u2193'\n",
    "    elif record['action'] == 2:\n",
    "        action = '\\u2192'\n",
    "    elif record['action'] == 3:\n",
    "        action = '\\u2190'\n",
    "\n",
    "    for i in range(record['region'][3] - record['region'][2]+1):\n",
    "        state = [0, 0]\n",
    "        state[record['region'][0]] = record['region'][1]\n",
    "        state[not record['region'][0]] = record['region'][2] + i\n",
    "        \n",
    "        # ensure we do not enter duplicate states\n",
    "        found = 0\n",
    "        for pair in action_states:\n",
    "            if pair['state'] == (state[0], state[1]):\n",
    "                found = 1\n",
    "                \n",
    "        if found == 0:\n",
    "            action_states.append({'state': (state[0], state[1]), 'action': action, 'q': record['q'] })\n",
    "\n",
    "# add in the rest of the states, either they are not visited, or illegal\n",
    "for n in reversed(range(env.rows)):\n",
    "    for m in range(env.cols):\n",
    "        action = ''\n",
    "        found = 0\n",
    "        for record in action_states:\n",
    "            if record['state'] == (n, m):\n",
    "                found = 1\n",
    "                action = record['action']\n",
    "#                 action = float(round(record['q'], 0))\n",
    "        if found == 0:\n",
    "            if not env.check_legal((n, m)):\n",
    "                action = 'X'\n",
    "            else:\n",
    "                action = '?'\n",
    "        print(f'{action} ', end='')\n",
    "    print('\\n')\n",
    "    \n",
    "\n",
    "q_map = np.zeros((env.rows, env.cols))\n",
    "\n",
    "# add in the rest of the states, either they are not visited, or illegal\n",
    "for n in range(env.rows):\n",
    "    for m in range(env.cols):\n",
    "        action = ''\n",
    "        found = 0\n",
    "        for record in action_states:\n",
    "            if record['state'] == (n, m):\n",
    "                found = 1\n",
    "                action = record['q']\n",
    "        if found == 0:\n",
    "            if not env.check_legal((n, m)):\n",
    "                action = -1\n",
    "            else:\n",
    "                action = 0\n",
    "        q_map[(env.rows-1)-n][m] = action\n",
    "\n",
    "plt.imshow(q_map, cmap='Blues', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(env.cols):\n",
    "    x.append(i)\n",
    "    y.append(i)\n",
    "\n",
    "Y, X = np.meshgrid(x, y)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# syntax for 3-D plotting\n",
    "ax = plt.axes(projection ='3d')\n",
    "\n",
    "# syntax for plotting\n",
    "ax.plot_surface(X, Y, q_map, cmap ='viridis', edgecolor ='green')\n",
    "ax.set_title(f'Surface plot for {envName}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap (RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_action_scores = []\n",
    "for learner in team.learners:\n",
    "    if learner.program.rule.value_set[0] > learner.program.rule.value_set[1]:\n",
    "        region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[0], 'q': learner.program.rule.value_set[0]})\n",
    "    else:\n",
    "        region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[1], 'q': learner.program.rule.value_set[1]})\n",
    "\n",
    "sorted_region_action_scores = sorted(region_action_scores, key=lambda value: float(value['q']), reverse=True)\n",
    "\n",
    "state_counts = []\n",
    "\n",
    "for n in reversed(range(env.rows)):\n",
    "    for m in range(env.cols):\n",
    "        state_count = 0\n",
    "        for record in sorted_region_action_scores:\n",
    "            for i in range(record['region'][3] - record['region'][2]+1):\n",
    "                state = [0, 0]\n",
    "                state[record['region'][0]] = record['region'][1]\n",
    "                state[not record['region'][0]] = record['region'][2] + i\n",
    "\n",
    "                if state == [n, m]:\n",
    "                    state_count += 1\n",
    "                # state count logic goes here\n",
    "        state_counts.append({'state': (n, m), 'count': state_count})\n",
    "\n",
    "for n in reversed(range(env.rows)):\n",
    "    for m in range(env.cols):\n",
    "        for record in state_counts:\n",
    "            if (n, m) == record['state']:\n",
    "                count = record['count']\n",
    "                print(f'{count} ', end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(team.gp_query_env)\n",
    "print(gp_query_env)\n",
    "print(rl_query_env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
