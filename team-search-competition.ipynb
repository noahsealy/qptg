{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qtpg.team import Team\n",
    "from qtpg.learner import Learner\n",
    "from qtpg.program import Program\n",
    "from qtpg.rule import Rule\n",
    "from qtpg.figure13 import Figure13\n",
    "from qtpg.figure13_hole_in_wall import Figure13HoleInWall\n",
    "from qtpg.figure12 import Figure12\n",
    "from qtpg.figure9 import Figure9\n",
    "from qtpg.figureRandom import FigureRandom\n",
    "from qtpg.figureHeywood import FigureHeywood\n",
    "from qtpg.search_manager import SearchManager\n",
    "import numpy as np\n",
    "import uuid\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_query_env = 0\n",
    "rl_query_env = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 20\n",
      "Columns: 20\n",
      "Start State: (11, 18)\n",
      "Win State: (9, 1)\n",
      "Illegal States: [(2, 14), (18, 5), (4, 1), (13, 8), (2, 12), (16, 9), (12, 14), (17, 0), (4, 13), (8, 6), (11, 9), (4, 6), (19, 5), (12, 13), (5, 15), (18, 17), (3, 9), (16, 8), (8, 13), (17, 9), (3, 6), (4, 12), (14, 0), (5, 6), (14, 7), (12, 6), (5, 10), (6, 10), (5, 7), (0, 7), (10, 9), (9, 18), (15, 12), (14, 3), (18, 6), (5, 14), (13, 7), (18, 0), (10, 11), (8, 11), (11, 4), (0, 2), (0, 1), (4, 7), (13, 9), (18, 1), (1, 2), (1, 6), (15, 15), (17, 1), (10, 5), (14, 2), (7, 19), (7, 18), (0, 14), (0, 0), (19, 7), (1, 13), (15, 14), (2, 3), (2, 6), (3, 14), (8, 12), (3, 3), (19, 6), (9, 17), (12, 4), (19, 11), (4, 0), (10, 16), (19, 18), (10, 18), (14, 12), (16, 1), (6, 7), (13, 3), (19, 14), (0, 8), (19, 8), (0, 10)]\n",
      "_ _ _ _ _ X X X X _ _ X _ _ X _ _ _ X _ \n",
      "\n",
      "X X _ _ _ X X _ _ _ _ _ _ _ _ _ _ X _ _ \n",
      "\n",
      "X X _ _ _ _ _ _ _ X _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ X _ _ _ _ _ _ X X _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ X _ X X _ _ _ _ \n",
      "\n",
      "X _ X X _ _ _ X _ _ _ _ X _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ X _ _ _ X X X _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ X _ X _ _ _ _ _ _ X X _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ X _ _ _ _ X _ _ _ _ _ _ _ _ S _ \n",
      "\n",
      "_ _ _ _ _ X _ _ _ X _ X _ _ _ _ X _ X _ \n",
      "\n",
      "_ W _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ X X _ \n",
      "\n",
      "_ _ _ _ _ _ X _ _ _ _ X X X _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ X X \n",
      "\n",
      "_ _ _ _ _ _ _ X _ _ X _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ X X _ _ X _ _ _ X X _ _ _ _ \n",
      "\n",
      "X X _ _ _ _ X X _ _ _ _ X X _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ X _ _ X _ _ X _ _ _ _ X _ _ _ _ _ \n",
      "\n",
      "_ _ _ X _ _ X _ _ _ _ _ X _ X _ _ _ _ _ \n",
      "\n",
      "_ _ X _ _ _ X _ _ _ _ _ _ X _ _ _ _ _ _ \n",
      "\n",
      "X X X _ _ _ _ X X _ X _ _ _ X _ _ _ _ _ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# env params\n",
    "memorySize = 40\n",
    "legalMove = 0.1\n",
    "illegalMove = -0.01\n",
    "outOfBounds = 0.0\n",
    "memoryRepeat = -0.01\n",
    "# memoryRepeat = 0.0\n",
    "goalReached = 100\n",
    "\n",
    "# envName = 'Figure 13'\n",
    "# env = Figure13(5, 5, (2, 4), (0, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Figure 13 Hole in Wall'\n",
    "# env = Figure13HoleInWall(5, 5, (2, 4), (0, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Figure 12'\n",
    "# env = Figure12(5, 5, (4, 4), (0, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Figure 9'\n",
    "# env = Figure9(10, 10, (4, 9), (0, 3), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "# envName = 'Heywood'\n",
    "# env = FigureHeywood(10, 10, (4, 4), (0, 4), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "envName = 'Random'\n",
    "env = FigureRandom(20, 20, memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "env.shake(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving env...\n",
      "Env saved successfully!\n",
      "89243945-e2d6-4cf9-9912-5e4fdcfda65d\n"
     ]
    }
   ],
   "source": [
    "env.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading env...\n",
      "Env loaded successfully!\n",
      "Rows: 20\n",
      "Columns: 20\n",
      "Start State: (0, 18)\n",
      "Win State: (9, 3)\n",
      "Illegal States: [(2, 2), (2, 3), (2, 15), (19, 16), (13, 15), (3, 19), (8, 15), (9, 13), (0, 6), (2, 4), (8, 17), (13, 12), (17, 14), (13, 19), (0, 7), (11, 6), (16, 18), (18, 12), (11, 0), (6, 8), (2, 1), (14, 6), (9, 19), (17, 8), (12, 2), (4, 8), (16, 5), (16, 3), (6, 7), (12, 5), (19, 13), (9, 15), (16, 16), (11, 8), (14, 15), (11, 3), (14, 10), (15, 7), (4, 7), (8, 13), (0, 15), (15, 15), (6, 9), (14, 7), (1, 12), (8, 2), (14, 8), (10, 13), (9, 2), (6, 15), (6, 6), (18, 14), (1, 13), (14, 9), (13, 18), (2, 13), (6, 11), (5, 17), (7, 10), (15, 8), (15, 14), (6, 3), (2, 16), (18, 5), (10, 12), (3, 5), (2, 7), (1, 1), (2, 0), (5, 19), (8, 11), (18, 1), (13, 5), (8, 12), (5, 5), (1, 7), (14, 5), (9, 12), (2, 8), (1, 10)]\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ X _ _ X _ _ _ \n",
      "\n",
      "_ X _ _ _ X _ _ _ _ _ _ X _ X _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ _ _ X _ _ _ _ _ X _ _ _ _ _ \n",
      "\n",
      "_ _ _ X _ X _ _ _ _ _ _ _ _ _ _ X _ X _ \n",
      "\n",
      "_ _ _ _ _ _ _ X X _ _ _ _ _ X X _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ X X X X X X _ _ _ _ X _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ X _ _ _ _ _ _ X _ _ X _ _ X X \n",
      "\n",
      "_ _ X _ _ X _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "X _ _ X _ _ X _ X _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ X X _ _ _ _ _ _ \n",
      "\n",
      "_ _ X W _ _ _ _ _ _ _ _ X X _ X _ _ _ X \n",
      "\n",
      "_ _ X _ _ _ _ _ _ _ _ X X X _ X _ X _ _ \n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ X _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ X _ _ X X X X _ X _ _ _ X _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ X _ _ _ _ _ _ _ _ _ _ _ X _ X \n",
      "\n",
      "_ _ _ _ _ _ _ X X _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ X _ _ _ _ _ _ _ _ _ _ _ _ _ X \n",
      "\n",
      "X X X X X _ _ X X _ _ _ _ X _ X X _ _ _ \n",
      "\n",
      "_ X _ _ _ _ _ X _ _ X _ X X _ _ _ _ _ _ \n",
      "\n",
      "_ _ _ _ _ _ X X _ _ _ _ _ _ _ X _ _ S _ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.load('990993d3-bafb-40d3-89e6-27869ed77ca8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numGens = 100\n",
    "maxTeamPool = 10\n",
    "runs = 1\n",
    "# init search manager and starting teams\n",
    "\n",
    "# searchManager = SearchManager(maxTeamPool)\n",
    "\n",
    "# variables for tracking fitness, for curves\n",
    "scores = []\n",
    "gens = []\n",
    "maxes = []\n",
    "averages = []\n",
    "mins = []\n",
    "\n",
    "run_winners = []\n",
    "runs_score_track = []\n",
    "\n",
    "for run in range(runs):\n",
    "    maxes = []\n",
    "    averages = []\n",
    "    mins = []\n",
    "    gens = []\n",
    "    print(run)\n",
    "    # init everything for new run\n",
    "    searchManager = SearchManager(maxTeamPool)\n",
    "    \n",
    "    adam_and_eve = []\n",
    "    env.reset()\n",
    "    init_team = Team(uuid.uuid4(), 0, 0, 1, 1, 0)\n",
    "    init_team.init_search(env, [2, 3])\n",
    "    adam_and_eve.append(init_team)\n",
    "    init_team = Team(uuid.uuid4(), 0, 0, 1, 1, 0)\n",
    "    init_team.init_search(env, [0, 1])\n",
    "    adam_and_eve.append(init_team)\n",
    "    win = False\n",
    "    for adam in adam_and_eve:\n",
    "        data = [adam, win]\n",
    "        searchManager.evaluate_team(data)\n",
    "    \n",
    "    \n",
    "    for gen in range(numGens):\n",
    "        print('winners so far:')\n",
    "        print(searchManager.winners)\n",
    "        print(f'GEN --> {gen}')\n",
    "        toEvaluateAfterGen = []\n",
    "        scores = []\n",
    "        # get it started\n",
    "        for parent in searchManager.teamPool:\n",
    "            # only run if the team has not yet won\n",
    "            if parent not in searchManager.winners:\n",
    "                env.current_state = parent.start_state\n",
    "\n",
    "                # make offspring from parent, then let that offspring make a new rule\n",
    "                child = copy.deepcopy(parent)\n",
    "                child.gp_query_env = parent.gp_query_env # probably don't need this, can test later\n",
    "                child.id = uuid.uuid4()\n",
    "                win = child.search_no_back_track(env)\n",
    "                \n",
    "                if child.mostRecent.program.rule.region[3] - child.mostRecent.program.rule.region[2] >= 0:\n",
    "                    gp_query_env += (child.mostRecent.program.rule.region[3] - child.mostRecent.program.rule.region[2]) + 1\n",
    "                toEvaluateAfterGen.append([child, win])\n",
    "                scores.append(child)\n",
    "            else:\n",
    "                scores.append(parent)\n",
    "\n",
    "        for data in toEvaluateAfterGen:\n",
    "            searchManager.evaluate_team(data)\n",
    "        # start: manage fitness curves (at end of gen)\n",
    "        gens.append(gen)\n",
    "        total = 0\n",
    "        max_fitness = -100\n",
    "        min_fitness = 100\n",
    "\n",
    "        for team in scores:\n",
    "            total += team.fitness\n",
    "            if team.fitness > max_fitness:\n",
    "                max_fitness = team.fitness\n",
    "            if team.fitness < min_fitness:\n",
    "                min_fitness = team.fitness\n",
    "        average_fitness = total / len(searchManager.teamPool)\n",
    "        maxes.append(max_fitness)\n",
    "        averages.append(average_fitness)\n",
    "        mins.append(min_fitness)\n",
    "\n",
    "    runs_score_track.append({'run': run, 'maxes': maxes, 'averages': averages, 'mins': mins})\n",
    "    \n",
    "    run_winners.append({'run': run, 'winners': searchManager.winners})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitness curves\n",
    "# x = []\n",
    "# y = []\n",
    "# for gen in gens:\n",
    "#     x.append(gen)\n",
    "\n",
    "# for average in averages:\n",
    "#     y.append(average)\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Average Score')\n",
    "# plt.plot(x, y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fitness curves\n",
    "# x = []\n",
    "# y = []\n",
    "# for gen in gens:\n",
    "#     x.append(gen)\n",
    "\n",
    "# for max_ in maxes:\n",
    "#     y.append(max_)\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Max Score')\n",
    "# plt.plot(x, y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for team in searchManager.winners:\n",
    "    print('$$$$$$$$$$$$$ winnnnnner start $$$$$$$$$$$$$$$$$$$$')\n",
    "    print(team.fitness)\n",
    "    print('Learners:')\n",
    "    for learner in team.learners:\n",
    "        print(f'Region: {learner.program.rule.region} --> Action: {learner.program.rule.action_set}')\n",
    "    print('$$$$$$$$$$$$$ winnnnnner end $$$$$$$$$$$$$$$$$$$$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for team in searchManager.winners:\n",
    "    # importing libraries\n",
    "    from mpl_toolkits import mplot3d\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    region_action_scores = []\n",
    "    for learner in team.learners:\n",
    "        if learner.program.rule.value_set[0] > learner.program.rule.value_set[1]:\n",
    "            region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[0], 'q': learner.program.rule.value_set[0]})\n",
    "        else:\n",
    "            region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[1], 'q': learner.program.rule.value_set[1]})\n",
    "\n",
    "    sorted_region_action_scores = sorted(region_action_scores, key=lambda value: float(value['q']), reverse=True)\n",
    "    # print(sorted_region_action_scores)\n",
    "    # for record in sorted_region_action_scores:\n",
    "    #     print(record)\n",
    "    action_states = []\n",
    "    for record in sorted_region_action_scores:\n",
    "        action = ''\n",
    "        if record['action'] == 0:\n",
    "            action = '\\u2191'\n",
    "        elif record['action'] == 1:\n",
    "            action = '\\u2193'\n",
    "        elif record['action'] == 2:\n",
    "            action = '\\u2192'\n",
    "        elif record['action'] == 3:\n",
    "            action = '\\u2190'\n",
    "\n",
    "        for i in range(record['region'][3] - record['region'][2]+1):\n",
    "            state = [0, 0]\n",
    "            state[record['region'][0]] = record['region'][1]\n",
    "            state[not record['region'][0]] = record['region'][2] + i\n",
    "\n",
    "            # ensure we do not enter duplicate states\n",
    "            found = 0\n",
    "            for pair in action_states:\n",
    "                if pair['state'] == (state[0], state[1]):\n",
    "                    found = 1\n",
    "\n",
    "            if found == 0:\n",
    "                action_states.append({'state': (state[0], state[1]), 'action': action, 'q': record['q'] })\n",
    "\n",
    "    # add in the rest of the states, either they are not visited, or illegal\n",
    "    for n in reversed(range(env.rows)):\n",
    "        for m in range(env.cols):\n",
    "            action = ''\n",
    "            found = 0\n",
    "            for record in action_states:\n",
    "                if record['state'] == (n, m):\n",
    "                    found = 1\n",
    "                    action = record['action']\n",
    "    #                 action = float(round(record['q'], 0))\n",
    "            if found == 0:\n",
    "                if not env.check_legal((n, m)):\n",
    "                    action = 'X'\n",
    "                else:\n",
    "                    action = '?'\n",
    "            print(f'{action} ', end='')\n",
    "        print('\\n')\n",
    "    print('------------NEW WINNER ----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Max Fitness Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(runs_score_track[0]['maxes'][0])\n",
    "print(len(runs_score_track))\n",
    "print(len(runs_score_track[0]))\n",
    "print(len(runs_score_track[0]['maxes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitness curves\n",
    "x = []\n",
    "y = []\n",
    "average_maxes = np.zeros(numGens)\n",
    "# average_maxes = np.zeros(100)\n",
    "\n",
    "for i in range(len(gens)):\n",
    "    for q in range(len(runs_score_track)):\n",
    "        average_maxes[i] += runs_score_track[q]['maxes'][i]\n",
    "    average_maxes[i] /= len(runs_score_track)\n",
    "    \n",
    "for gen in gens:\n",
    "    x.append(gen)\n",
    "\n",
    "plt.title(f'Average max score over {len(runs_score_track)} runs for {envName}')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Average Max Score')\n",
    "plt.plot(x, average_maxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning + Victory Lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(run_winners)\n",
    "for winner in run_winners[0]['winners']:\n",
    "    for learner in winner.learners:\n",
    "        print(learner.program.rule.region)\n",
    "    print('\\n\\n\\n')\n",
    "# for learner in team.learners:\n",
    "#     print(learner.program.rule.region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(run_winners[0]['winners'])):\n",
    "    for learner in run_winners[0]['winners'][i].learners:\n",
    "        print(learner.id)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# team = searchManager.winners[0]\n",
    "team = run_winners[0]['winners'][0]\n",
    "team.discount = 0.9\n",
    "team.alpha = 0.5\n",
    "# for learner in team.learners:\n",
    "#     print(learner.program.rule.region)\n",
    "\n",
    "# team.prune_single_cell_regions() # don't think this is good...\n",
    "team.prune_duplicate_regions()\n",
    "\n",
    "for i in range(env.rows):\n",
    "#     print(f'Epoch: {i+1} --------')\n",
    "    env.reset()\n",
    "#     print(f'curr -> {env.current_state}')\n",
    "    win = False\n",
    "    selected_learner = team.select_learner(env, [0, 0, 0, 0])\n",
    "    while not win:\n",
    "        win, needs_update, reward, winning_action = team.q_evaluation(env, selected_learner)\n",
    "#         print(reward)\n",
    "#         print('hi')\n",
    "        if not win:\n",
    "            selected_learner = team.select_learner(env, selected_learner.program.rule.region)\n",
    "            team.transition_update(reward, winning_action, needs_update, selected_learner)\n",
    "            rl_query_env += 1\n",
    "\n",
    "    team.final_update(reward, winning_action, needs_update)\n",
    "\n",
    "print(win)\n",
    "for learner in team.learners:\n",
    "    print(f'{learner.program.rule.region}')\n",
    "    for i in range(len(learner.program.rule.action_set)):\n",
    "          print(f'{learner.program.rule.action_set[i]} --> {learner.program.rule.value_set[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Action Map (RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "region_action_scores = []\n",
    "for learner in team.learners:\n",
    "    if learner.program.rule.value_set[0] > learner.program.rule.value_set[1]:\n",
    "        region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[0], 'q': learner.program.rule.value_set[0]})\n",
    "    else:\n",
    "        region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[1], 'q': learner.program.rule.value_set[1]})\n",
    "\n",
    "sorted_region_action_scores = sorted(region_action_scores, key=lambda value: float(value['q']), reverse=True)\n",
    "# print(sorted_region_action_scores)\n",
    "# for record in sorted_region_action_scores:\n",
    "#     print(record)\n",
    "action_states = []\n",
    "for record in sorted_region_action_scores:\n",
    "    action = ''\n",
    "    if record['action'] == 0:\n",
    "        action = '\\u2191'\n",
    "    elif record['action'] == 1:\n",
    "        action = '\\u2193'\n",
    "    elif record['action'] == 2:\n",
    "        action = '\\u2192'\n",
    "    elif record['action'] == 3:\n",
    "        action = '\\u2190'\n",
    "\n",
    "    for i in range(record['region'][3] - record['region'][2]+1):\n",
    "        state = [0, 0]\n",
    "        state[record['region'][0]] = record['region'][1]\n",
    "        state[not record['region'][0]] = record['region'][2] + i\n",
    "        \n",
    "        # ensure we do not enter duplicate states\n",
    "        found = 0\n",
    "        for pair in action_states:\n",
    "            if pair['state'] == (state[0], state[1]):\n",
    "                found = 1\n",
    "                \n",
    "        if found == 0:\n",
    "            action_states.append({'state': (state[0], state[1]), 'action': action, 'q': record['q'] })\n",
    "\n",
    "# add in the rest of the states, either they are not visited, or illegal\n",
    "for n in reversed(range(env.rows)):\n",
    "    for m in range(env.cols):\n",
    "        action = ''\n",
    "        found = 0\n",
    "        for record in action_states:\n",
    "            if record['state'] == (n, m):\n",
    "                found = 1\n",
    "                action = record['action']\n",
    "#                 action = float(round(record['q'], 0))\n",
    "        if found == 0:\n",
    "            if not env.check_legal((n, m)):\n",
    "                action = 'X'\n",
    "            else:\n",
    "                action = '?'\n",
    "        print(f'{action} ', end='')\n",
    "    print('\\n')\n",
    "    \n",
    "\n",
    "q_map = np.zeros((env.rows, env.cols))\n",
    "\n",
    "# add in the rest of the states, either they are not visited, or illegal\n",
    "for n in range(env.rows):\n",
    "    for m in range(env.cols):\n",
    "        action = ''\n",
    "        found = 0\n",
    "        for record in action_states:\n",
    "            if record['state'] == (n, m):\n",
    "                found = 1\n",
    "                action = record['q']\n",
    "        if found == 0:\n",
    "            if not env.check_legal((n, m)):\n",
    "                action = -1\n",
    "            else:\n",
    "                action = 0\n",
    "        q_map[(env.rows-1)-n][m] = action\n",
    "\n",
    "plt.imshow(q_map, cmap='Blues', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(env.cols):\n",
    "    x.append(i)\n",
    "    y.append(i)\n",
    "\n",
    "Y, X = np.meshgrid(x, y)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# syntax for 3-D plotting\n",
    "ax = plt.axes(projection ='3d')\n",
    "\n",
    "# syntax for plotting\n",
    "ax.plot_surface(X, Y, q_map, cmap ='viridis', edgecolor ='green')\n",
    "ax.set_title(f'Surface plot for {envName}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap (RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_action_scores = []\n",
    "for learner in team.learners:\n",
    "    if learner.program.rule.value_set[0] > learner.program.rule.value_set[1]:\n",
    "        region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[0], 'q': learner.program.rule.value_set[0]})\n",
    "    else:\n",
    "        region_action_scores.append({'region': learner.program.rule.region, 'action': learner.program.rule.action_set[1], 'q': learner.program.rule.value_set[1]})\n",
    "\n",
    "sorted_region_action_scores = sorted(region_action_scores, key=lambda value: float(value['q']), reverse=True)\n",
    "\n",
    "state_counts = []\n",
    "\n",
    "for n in reversed(range(env.rows)):\n",
    "    for m in range(env.cols):\n",
    "        state_count = 0\n",
    "        for record in sorted_region_action_scores:\n",
    "            for i in range(record['region'][3] - record['region'][2]+1):\n",
    "                state = [0, 0]\n",
    "                state[record['region'][0]] = record['region'][1]\n",
    "                state[not record['region'][0]] = record['region'][2] + i\n",
    "\n",
    "                if state == [n, m]:\n",
    "                    state_count += 1\n",
    "                # state count logic goes here\n",
    "        state_counts.append({'state': (n, m), 'count': state_count})\n",
    "\n",
    "for n in reversed(range(env.rows)):\n",
    "    for m in range(env.cols):\n",
    "        for record in state_counts:\n",
    "            if (n, m) == record['state']:\n",
    "                count = record['count']\n",
    "                print(f'{count} ', end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(team.gp_query_env)\n",
    "print(gp_query_env)\n",
    "print(rl_query_env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
