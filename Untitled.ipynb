{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qtpg.team import Team\n",
    "from qtpg.agent import Agent\n",
    "from qtpg.trainer import Trainer\n",
    "from qtpg.figure13 import Figure13\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp params\n",
    "numLearners = 4\n",
    "numAgents = 1\n",
    "numRuns = 100\n",
    "numGens = 1000\n",
    "numEpisodes = 50\n",
    "gap = 0.3\n",
    "# rl params\n",
    "alpha, discount, epsilon = 0.9, 0.9, 0.1\n",
    "# env params\n",
    "memorySize = 20\n",
    "legalMove = 0.1\n",
    "illegalMove = -0.01\n",
    "outOfBounds = -0.01\n",
    "memoryRepeat = 0#-0.01\n",
    "goalReached = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rules = 10\n",
    "team = Team(0, numLearners, max_rules, alpha, discount, epsilon)\n",
    "# search tests\n",
    "\n",
    "env = Figure13(5, 5, (2, 4), (0, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "env.memoryRepeat = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_parent_region(parent_region, child_position, action):\n",
    "    # need to add in action checks to compensate for clipping\n",
    "    # the action should be able to start in the clipped part (... that's the whole point of clipping)\n",
    "    # it's safe here to assume the region is not out of bounds\n",
    "    if (action == 0 or action == 2) and child_position[parent_region[0]] == parent_region[1] and \\\n",
    "            parent_region[2] <= child_position[not parent_region[0]] <= (parent_region[3]+1):\n",
    "        return True\n",
    "    if (action == 1 or action == 3) and child_position[parent_region[0]] == parent_region[1] and \\\n",
    "            (parent_region[2]-1) <= child_position[not parent_region[0]] <= parent_region[3]:\n",
    "        return True\n",
    "    return False\n",
    "    # if child_position[parent_region[0]] == parent_region[1] and \\\n",
    "    #         (parent_region[2] <= child_position[not parent_region[0]] <= parent_region[3]):\n",
    "    #     return True\n",
    "    # return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4)\n",
      "0.1\n",
      "(0, 4)\n",
      "[1, 4, 0, 0]\n",
      "True\n",
      "hey\n",
      "backtracked\n",
      "(0, 4)\n",
      "new state --> (0, 4)\n",
      "(0, 4)\n",
      "[1, 4, 0, 0]\n",
      "(0, 4)\n",
      "hey\n",
      "backtracked\n",
      "(0, 4)\n",
      "new state --> (0, 4)\n",
      "(0, 4)\n",
      "[1, 4, 0, 0]\n",
      "(0, 4)\n",
      "hey\n",
      "backtracked\n",
      "(0, 4)\n",
      "new state --> (0, 4)\n",
      "(0, 4)\n",
      "[1, 4, 0, 0]\n",
      "(0, 4)\n",
      "hey\n",
      "backtracked\n",
      "(0, 4)\n",
      "new state --> (0, 4)\n",
      "(0, 4)\n",
      "[1, 4, 0, 0]\n",
      "(0, 4)\n",
      "hey\n",
      "backtracked\n",
      "(0, 4)\n",
      "new state --> (0, 4)\n",
      "(0, 4)\n",
      "[1, 4, 0, 0]\n",
      "(0, 4)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from qtpg.rule import Rule\n",
    "\n",
    "env.reset()\n",
    "action = 2\n",
    "state, reward, terminate = env.step(action)\n",
    "state, reward, terminate = env.step(action)\n",
    "state, reward, terminate = env.step(action)\n",
    "state, reward, terminate = env.step(action)\n",
    "print(env.current_state)\n",
    "print(reward)\n",
    "\n",
    "action = 2\n",
    "region = [0, 0, 0, 0]\n",
    "selected_rule = Rule(-1, [1, 4, 0, 0], 1, 0)\n",
    "\n",
    "updated_parent = copy.deepcopy(selected_rule)\n",
    "\n",
    "print(env.current_state)\n",
    "print(updated_parent.region)\n",
    "print(in_parent_region(updated_parent.region, env.current_state, 0))\n",
    "\n",
    "state, reward, terminate = env.step(action)\n",
    "\n",
    "backTrackLimit = 0\n",
    "while (reward >= 0 or (reward < 0 and in_parent_region(updated_parent.region, env.current_state, action))) \\\n",
    "        and backTrackLimit < 5:\n",
    "    print('hey')\n",
    "    backTrackLimit += 1\n",
    "    # while reward >= 0:\n",
    "    # if the team is within the region of the previous rule, we need to backtrack (and not set a region)\n",
    "    if reward < 0 and in_parent_region(updated_parent.region, env.current_state, action):\n",
    "        backTrack = True\n",
    "        print('backtracked')\n",
    "        print(env.current_state)\n",
    "        # if the state where backtracking is required is the lower bound\n",
    "        # if env.current_state[not updated_parent.region[0]] == updated_parent.region[2]:\n",
    "        if action == 1 or action == 3:\n",
    "            # backtrack the region bound, we add here as it is always a lower bound\n",
    "            if updated_parent.region[2] < 4:\n",
    "                updated_parent.region[2] = updated_parent.region[2] + 1\n",
    "            if updated_parent.region[0] == 1:\n",
    "                # update the env state\n",
    "                new_state = (updated_parent.region[2], env.current_state[1])\n",
    "                print(f'new state --> {new_state}')\n",
    "                if (new_state != (2, 0)) and (new_state != (2, 1)) and (new_state != (3, 1)) and (\n",
    "                        new_state != (1, 3)) and (new_state != (2, 3)) and (new_state != (3, 3)) and (\n",
    "                        new_state != (1, 4)):\n",
    "                    env.current_state = new_state\n",
    "                    region[1] = env.current_state[0]\n",
    "            else:\n",
    "                new_state = (env.current_state[0], updated_parent.region[2])\n",
    "                print(f'new state --> {new_state}')\n",
    "                if (new_state != (2, 0)) and (new_state != (2, 1)) and (new_state != (3, 1)) and (\n",
    "                        new_state != (1, 3)) and (new_state != (2, 3)) and (new_state != (3, 3)) and (\n",
    "                        new_state != (1, 4)):\n",
    "                    env.current_state = new_state\n",
    "                    region[1] = env.current_state[1]\n",
    "\n",
    "        # coord that we're not keeping constant must equal the upper bound\n",
    "        else:\n",
    "            # backtrack the region bound, we subtract here as it is always an upper bound\n",
    "            if updated_parent.region[3] > 0:\n",
    "                updated_parent.region[3] = updated_parent.region[3] - 1\n",
    "            # correct the position of the agent, tuples are immutable...\n",
    "            if updated_parent.region[0] == 1:\n",
    "                # soon, this will be replaced by just having the searcher step into the env\n",
    "                # that way, we don't have to call these checks...\n",
    "                new_state = (updated_parent.region[3], env.current_state[1])\n",
    "                print(f'new state --> {new_state}')\n",
    "                if (new_state != (2, 0)) and (new_state != (2, 1)) and (new_state != (3, 1)) and (\n",
    "                        new_state != (1, 3)) and (new_state != (2, 3)) and (new_state != (3, 3)) and (\n",
    "                        new_state != (1, 4)):\n",
    "                    env.current_state = new_state\n",
    "                    region[1] = env.current_state[0]\n",
    "            else:\n",
    "                # search_space.current_state = (prev_rule.region[3], search_space.current_state[0])\n",
    "                new_state = (env.current_state[0], updated_parent.region[3])\n",
    "                print(f'new state --> {new_state}')\n",
    "                if (new_state != (2, 0)) and (new_state != (2, 1)) and (new_state != (3, 1)) and (\n",
    "                        new_state != (1, 3)) and (new_state != (2, 3)) and (new_state != (3, 3)) and (\n",
    "                        new_state != (1, 4)):\n",
    "                    env.current_state = new_state\n",
    "                    region[1] = env.current_state[1]\n",
    "\n",
    "    state, reward, terminate = env.step(action)\n",
    "    print(env.current_state)\n",
    "    print(updated_parent.region)\n",
    "    print(env.current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "test = random.randint(0, 0)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
